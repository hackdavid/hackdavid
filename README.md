<h1 align="center">Daud Ibrahim</h1>

<p align="center">
  <b>Senior Machine Learning Engineer | Applied AI | LLM Systems</b>
</p>

<p align="center">
  Building production-grade AI systems with real-world scale, cost constraints, and reliability requirements.
</p>

---

### ğŸš€ Profile Snapshot

<table>
  <tr>
    <td><b>Focus</b></td>
    <td>Applied AI, LLM systems, ML infrastructure</td>
  </tr>
  <tr>
    <td><b>Experience</b></td>
    <td>End-to-end ownership from data and training to inference and APIs</td>
  </tr>
  <tr>
    <td><b>Scale</b></td>
    <td>High-throughput systems, distributed GPU training, low-latency serving</td>
  </tr>
  <tr>
    <td><b>Mindset</b></td>
    <td>Production realism, measurable impact, long-term maintainability</td>
  </tr>
</table>

---

### ğŸ§  What I Work On

I design, build, and operate **applied AI systems** that move beyond experimentation into real production use.

My work spans:
- Large language models and multimodal systems
- Distributed training and inference optimization
- ML platforms integrated with backend and product workflows
- Evaluation, benchmarking, and regression-safe deployment

I am especially interested in problems where **model quality, system reliability, and cost efficiency must coexist**.

---

### ğŸ—ï¸ Selected Systems (Abstracted)

<table>
  <tr>
    <td>ğŸ“Š</td>
    <td>
      <b>AI-driven retail and analytics platforms</b><br/>
      Production systems improving operational visibility and decision-making across hundreds of stores
    </td>
  </tr>
  <tr>
    <td>ğŸ¤–</td>
    <td>
      <b>LLM-powered assistants and analytics engines</b><br/>
      Automated insight generation using multi-agent and retrieval-based workflows
    </td>
  </tr>
  <tr>
    <td>âš™ï¸</td>
    <td>
      <b>Large-scale language model training and inference</b><br/>
      Distributed GPU training, multilingual modeling, and optimized serving pipelines
    </td>
  </tr>
  <tr>
    <td>ğŸ“ˆ</td>
    <td>
      <b>Model evaluation and benchmarking pipelines</b><br/>
      Reliable comparison frameworks for quality, latency, and regression detection
    </td>
  </tr>
</table>

<p><i>Some systems are internal and described here at an architectural level.</i></p>

---

### ğŸ§° Technical Focus Areas

**ML and LLMs**
- PyTorch, TensorFlow, Hugging Face
- Fine-tuning, PEFT, LoRA, RLHF, DPO
- Multilingual and large-context models

**Systems and Infrastructure**
- Distributed GPU training and inference
- TensorRT-LLM, vLLM, DeepSpeed
- FastAPI-based model serving

**Production and MLOps**
- Docker, Kubernetes, cloud deployments
- CI/CD, monitoring, reliability practices
- Data pipelines, ETL, workflow orchestration

---

### ğŸ“ Engineering Principles

- Production impact over research demos  
- Simple abstractions that survive scale  
- Explicit evaluation and regression safety  
- Systems designed for long-term ownership  

---

### ğŸ“Œ Public Work

This profile highlights selected public repositories and system-level experience.
Pinned repositories reflect areas of active interest and production relevance.
